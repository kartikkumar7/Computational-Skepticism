# Computational-Skepticism

Making a model “​TrustWorthy​”. How to compute model interpretability for Linear Regression and Deep Learning using traditional statistical approach and automated machine learning.

## Problem statement

Making a machine trustworthy and reliable is one of the most important goals of data science today. Models are many times used as black boxes, wherein we give a particular input, know little of what happens inside the model, and get an output. But an important question that often gets overlooked is 'Why?' In some cases, one might not care why a decision was made, it is enough to know that the predictive performance on a test dataset was good. But in other cases, knowing the ‘Why’ can help learn more about the problem,the data and the reason why a model might fail. In cases such as cancer detection, self-driving cars or other critical places that can involve life and death, this becomes extremely crucial.

## Proposed solution

In this project we aim to build a system that can be used to transform an unassured model in to an assured and dependable one. We will uncover interpretability of a simple model and a complex model \(deep learning\). For both the cases, the model interpretability will be explained on the basis of Expressive Power, Translucency, Portability and Algorithmic complexity. Supporting code will also be provided to help showcase the theory in real-world applications. Establishing local interpretability for single predictions and group predictions using model-agnostic methods is the ultimate goal of this project.

## Project Members:

Abhishek Gargha Maheshwarappa

Kartik Kumar
